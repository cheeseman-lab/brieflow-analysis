{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df6bd89d",
   "metadata": {},
   "source": [
    "# Train Classifier\n",
    "\n",
    "This notebook provides tools for training custom cell or vacuole classifiers. It covers labeling data, training models, and selecting the best classifier.\n",
    "\n",
    "Cells marked with <font color='red'>SET PARAMETERS</font> contain crucial variables that need to be set according to your specific experimental setup and data organization.\n",
    "Please review and modify these variables as needed before proceeding with the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8862bf60",
   "metadata": {},
   "source": [
    "## <font color='red'>SET PARAMETERS</font>\n",
    "\n",
    "### Fixed parameters for aggregate module\n",
    "\n",
    "- `CONFIG_FILE_PATH`: Path to a Brieflow config file used during processing. Absolute or relative to where workflows are run from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6ec2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_FILE_PATH = \"config/config.yml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d227e3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yaml\n",
    "\n",
    "from lib.aggregate.cell_classification import CellClassifier\n",
    "from lib.aggregate.cell_data_utils import split_cell_data\n",
    "from lib.classify.apply import (\n",
    "    build_master_phenotype_df,\n",
    "    build_montages_and_summary,\n",
    "    display_pngs_in_plots_and_list_models,\n",
    "    launch_rankline_ui,\n",
    "    resolve_classifier_model_dill_path,\n",
    "    show_model_evaluation_pngs,\n",
    ")\n",
    "from lib.classify.calibration import calibrate_confidence\n",
    "from lib.classify.labeling import (\n",
    "    _ensure_mc_schema,\n",
    "    _mode_norm,\n",
    "    _normalize_keys,\n",
    "    _pq_path_for,\n",
    "    _render_next_batch,\n",
    "    consolidate_manual_classifications,\n",
    "    prepare_mask_dataframes,\n",
    ")\n",
    "from lib.classify.train import (\n",
    "    filter_classes,\n",
    "    load_cellprofiler_data,\n",
    "    train_classifier_pipeline,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b352cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(CONFIG_FILE_PATH, \"r\") as config_file:\n",
    "    config = yaml.safe_load(config_file)\n",
    "\n",
    "ROOT_FP = (Path(CONFIG_FILE_PATH).resolve().parent.parent / config[\"all\"][\"root_fp\"]).resolve()\n",
    "PHENOTYPE_OUTPUT_FP = ROOT_FP / \"phenotype\"\n",
    "PQ_DIR = PHENOTYPE_OUTPUT_FP / \"parquets\"\n",
    "\n",
    "CLASSIFIER_OUTPUT_DIR = ROOT_FP / \"classifier\"\n",
    "CLASSIFIER_OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "print(f\"Created/verified: {CLASSIFIER_OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bvw79449do",
   "metadata": {},
   "source": [
    "## 1. Labeling\n",
    "\n",
    "Use an interactive UI to label cells or vacuoles to create training data for machine learning models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3341b58f",
   "metadata": {},
   "source": [
    "### 1a. <font color='red'>SET PARAMETERS</font>: Classification Settings\n",
    "\n",
    "**If adding to an existing training dataset:**\n",
    "- `ADD_TRAINING_DATA`: Set to `False` for first-time training, `True` to add to an existing dataset.\n",
    "- `EXISTING_TRAINING_DATA`: Only set if `ADD_TRAINING_DATA` is `True`. Specify the filename of the existing training dataset.\n",
    "- `RELABEL_CLASSIFICATIONS`: Set to `True` to revisit and modify labels from the existing dataset. Previously labeled data will be shown first.\n",
    "\n",
    "**Classification parameters:**\n",
    "- `CLASSIFY_BY_VACUOLE_OR_CELL`: Set to `\"vacuole\"` or `\"cell\"`.\n",
    "- `CLASS_TITLE`: Name of the new column added to the phenotype dataframe.\n",
    "- `CLASSIFICATION`: List of categories for classification. Categories appear as 1, 2, 3... in output, corresponding to list order.\n",
    "- `PLATES_TO_CLASSIFY`: Plates to include in classification.\n",
    "- `WELLS_TO_CLASSIFY`: Wells among the specified plates to classify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3340edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ADD_TRAINING_DATA = True\n",
    "EXISTING_TRAINING_DATA = \"vacuole_classifier_training_dataset_for_parasite_count_20250818_002808.parquet\"\n",
    "RELABEL_CLASSIFICATIONS = True\n",
    "CLASSIFY_BY_VACUOLE_OR_CELL = \"vacuole\"\n",
    "CLASS_TITLE = \"parasite_count\"\n",
    "CLASSIFICATION = [\"1 parasite\", \"2-3 parasite\", \"4-7 parasite\", \"8+ parasite\"]\n",
    "PLATES_TO_CLASSIFY = [\"1\", \"2\"] \n",
    "WELLS_TO_CLASSIFY = [\"A1\", \"A2\", \"A3\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d422ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "_mode_cfg = str(CLASSIFY_BY_VACUOLE_OR_CELL).strip().lower()\n",
    "if _mode_cfg not in {\"cell\", \"vacuole\"}:\n",
    "    raise ValueError(f\"CLASSIFY_BY_VACUOLE_OR_CELL must be 'cell' or 'vacuole', got: {CLASSIFY_BY_VACUOLE_OR_CELL!r}\")\n",
    "\n",
    "EXISTING_TRAINING_PATH = None\n",
    "if ADD_TRAINING_DATA:\n",
    "    if not EXISTING_TRAINING_DATA:\n",
    "        raise ValueError(\"ADD_TRAINING_DATA=True but EXISTING_TRAINING_DATA is not provided (filename).\")\n",
    "    train_dir = Path(CLASSIFIER_OUTPUT_DIR) / \"training_dataset\"\n",
    "    EXISTING_TRAINING_PATH = train_dir / str(EXISTING_TRAINING_DATA)\n",
    "    if not EXISTING_TRAINING_PATH.exists():\n",
    "        raise FileNotFoundError(f\"Existing training parquet not found: {EXISTING_TRAINING_PATH}\")\n",
    "\n",
    "    m = re.match(r\"^(cell|vacuole)_classifier_training_dataset_for_(.+?)_\\d{8}_\\d{6}\\.parquet$\",\n",
    "                 EXISTING_TRAINING_PATH.name)\n",
    "    if not m:\n",
    "        raise ValueError(\n",
    "            \"EXISTING_TRAINING_DATA filename must match:\\n\"\n",
    "            \"  '{mode}_classifier_training_dataset_for_{CLASS_TITLE}_{YYYYMMDD}_{HHMMSS}.parquet'\"\n",
    "        )\n",
    "    mode_from_file = m.group(1)\n",
    "    class_title_from_file = m.group(2)\n",
    "\n",
    "    if mode_from_file != _mode_cfg:\n",
    "        raise ValueError(\n",
    "            f\"Mode mismatch: file says mode='{mode_from_file}', but CLASSIFY_BY_VACUOLE_OR_CELL='{_mode_cfg}'. \"\n",
    "            \"Please align your settings with the existing parquet.\"\n",
    "        )\n",
    "    if class_title_from_file != CLASS_TITLE:\n",
    "        raise ValueError(\n",
    "            f\"CLASS_TITLE mismatch: file says CLASS_TITLE='{class_title_from_file}', but CLASS_TITLE='{CLASS_TITLE}'. \"\n",
    "            \"Please align your settings with the existing parquet.\"\n",
    "        )\n",
    "    \n",
    "class_mapping = {'label_to_class': {i + 1: label for i, label in enumerate(CLASSIFICATION)}}\n",
    "\n",
    "print(\"[training] Config OK.\",\n",
    "      f\"ADD_TRAINING_DATA={ADD_TRAINING_DATA}, RELABEL_CLASSIFICATIONS={RELABEL_CLASSIFICATIONS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = _mode_norm(CLASSIFY_BY_VACUOLE_OR_CELL)\n",
    "plate_set = [str(p) for p in PLATES_TO_CLASSIFY]\n",
    "well_set = list(WELLS_TO_CLASSIFY)\n",
    "\n",
    "exclude_exact = {\"plate\", \"well\", \"tile\", \"vacuole_id\", \"label\"}\n",
    "ordered_features, seen = [], set()\n",
    "\n",
    "for plate in sorted(plate_set):\n",
    "    for well in sorted(well_set):\n",
    "        pq_path = _pq_path_for(plate, well, PQ_DIR, mode)\n",
    "        if not pq_path.exists():\n",
    "            continue\n",
    "        try:\n",
    "            import pyarrow.parquet as pq\n",
    "            cols = pq.ParquetFile(pq_path).schema.names\n",
    "        except Exception:\n",
    "            cols = list(pd.read_parquet(pq_path).head(0).columns)\n",
    "\n",
    "        for col in cols:\n",
    "            lc = str(col).lower()\n",
    "            if (\n",
    "                lc in exclude_exact\n",
    "                or (\"bounds\" in lc)\n",
    "                or (\"location\" in lc)\n",
    "                or re.fullmatch(r\"__index_level_\\d+__\", lc)\n",
    "            ):\n",
    "                continue\n",
    "            if col not in seen:\n",
    "                seen.add(col)\n",
    "                ordered_features.append(col)\n",
    "\n",
    "for name in ordered_features:\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd8ef59",
   "metadata": {},
   "source": [
    "### 1b. <font color='red'>SET PARAMETERS</font>: Threshold Settings\n",
    "\n",
    "**Feature thresholding (optional):**\n",
    "- `THRESHOLD_FEATURE`: Feature to threshold by (e.g., `\"nucleus_DAPI_mean\"`). Set to `None` to skip thresholding.\n",
    "- `THRESHOLD_MIN`: Minimum value (exclusive). Masks below this will not be displayed.\n",
    "- `THRESHOLD_MAX`: Maximum value (inclusive). Masks above this will not be displayed.\n",
    "- `THRESHOLD_MIN_PERCENTILE`: Percentile minimum (0-1). Masks below this percentile will not be displayed.\n",
    "- `THRESHOLD_MAX_PERCENTILE`: Percentile maximum (0-1). Masks above this percentile will not be displayed.\n",
    "\n",
    "**Batch settings:**\n",
    "- `BATCH_SIZE`: Number of images to display per round of classification. Default is 10.\n",
    "- `OUT_OF_THRESHOLD_RANDOMIZER`: Number of out-of-threshold images to include per batch (0 to `BATCH_SIZE`). Default is 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab5ee63",
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLD_FEATURE = \"vacuole_area_x\"\n",
    "THRESHOLD_MIN = None\n",
    "THRESHOLD_MAX = 11600\n",
    "THRESHOLD_MIN_PERCENTILE = 0.5\n",
    "THRESHOLD_MAX_PERCENTILE = None\n",
    "BATCH_SIZE = 10\n",
    "OUT_OF_THRESHOLD_RANDOMIZER = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025e1921",
   "metadata": {},
   "outputs": [],
   "source": [
    "_KEYS = [\"plate\", \"well\", \"tile\", \"mask_label\"]\n",
    "\n",
    "mask_summary_df, mask_instances_df, mask_instances_out_of_threshold_df, thr_dbg = prepare_mask_dataframes(\n",
    "    mode=CLASSIFY_BY_VACUOLE_OR_CELL,\n",
    "    pq_root=PHENOTYPE_OUTPUT_FP,\n",
    "    plates=PLATES_TO_CLASSIFY,\n",
    "    wells=WELLS_TO_CLASSIFY,\n",
    "    keys=_KEYS,\n",
    "    threshold_feature=THRESHOLD_FEATURE,\n",
    "    threshold_min=THRESHOLD_MIN,\n",
    "    threshold_max=THRESHOLD_MAX,\n",
    "    threshold_min_percentile=THRESHOLD_MIN_PERCENTILE,\n",
    "    threshold_max_percentile=THRESHOLD_MAX_PERCENTILE,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ADD_TRAINING_DATA:\n",
    "    df_existing = pd.read_parquet(EXISTING_TRAINING_PATH)\n",
    "    seeded = _normalize_keys(df_existing, _mode_cfg, CLASS_TITLE)\n",
    "    seeded[\"_existing\"] = True\n",
    "\n",
    "    if \"_STATE\" in globals():\n",
    "        if _STATE.get(\"manual_classified_df\") is None:\n",
    "            _STATE[\"manual_classified_df\"] = seeded.copy()\n",
    "        else:\n",
    "            _STATE[\"manual_classified_df\"] = (\n",
    "                pd.concat([_STATE[\"manual_classified_df\"], seeded], ignore_index=True)\n",
    "                  .drop_duplicates(subset=[\"plate\",\"well\",\"tile\",\"mask_label\"], keep=\"last\")\n",
    "            )\n",
    "        if _STATE.get(\"manual_unclassified_df\") is None:\n",
    "            _STATE[\"manual_unclassified_df\"] = pd.DataFrame(columns=[\"plate\",\"well\",\"tile\",\"mask_label\"])\n",
    "    else:\n",
    "        manual_classified_df = seeded.copy()\n",
    "        manual_unclassified_df = pd.DataFrame(columns=[\"plate\",\"well\",\"tile\",\"mask_label\"])\n",
    "\n",
    "    _EXISTING_KEYS = set((int(r.plate), str(r.well), int(r.tile), int(r.mask_label))\n",
    "                         for r in seeded.itertuples(index=False))\n",
    "else:\n",
    "    _EXISTING_KEYS = set()\n",
    "\n",
    "if ADD_TRAINING_DATA and not RELABEL_CLASSIFICATIONS:\n",
    "    if not mask_instances_df.empty:\n",
    "        mask_instances_df = mask_instances_df.merge(\n",
    "            pd.DataFrame(list(_EXISTING_KEYS), columns=[\"plate\",\"well\",\"tile\",\"mask_label\"])\n",
    "              .assign(_ex=1),\n",
    "            on=[\"plate\",\"well\",\"tile\",\"mask_label\"], how=\"left\"\n",
    "        )\n",
    "        mask_instances_df = mask_instances_df[mask_instances_df[\"_ex\"].isna()].drop(columns=\"_ex\").reset_index(drop=True)\n",
    "    if not mask_instances_out_of_threshold_df.empty:\n",
    "        mask_instances_out_of_threshold_df = mask_instances_out_of_threshold_df.merge(\n",
    "            pd.DataFrame(list(_EXISTING_KEYS), columns=[\"plate\",\"well\",\"tile\",\"mask_label\"])\n",
    "              .assign(_ex=1),\n",
    "            on=[\"plate\",\"well\",\"tile\",\"mask_label\"], how=\"left\"\n",
    "        )\n",
    "        mask_instances_out_of_threshold_df = mask_instances_out_of_threshold_df[\n",
    "            mask_instances_out_of_threshold_df[\"_ex\"].isna()\n",
    "        ].drop(columns=\"_ex\").reset_index(drop=True)\n",
    "\n",
    "print(\"[training] Existing keys in session:\", len(_EXISTING_KEYS))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a04d35",
   "metadata": {},
   "source": [
    "### 1c. <font color='red'>SET PARAMETERS</font>: Display Settings\n",
    "\n",
    "**Channel visualization:**\n",
    "- `DISPLAY_CHANNEL`: Channels to display for manual classification.\n",
    "- `CHANNEL_COLORS`: Colors for each channel. Must align with `DISPLAY_CHANNEL` order. See [matplotlib colors](https://matplotlib.org/stable/gallery/color/named_colors.html).\n",
    "\n",
    "**Selection method:**\n",
    "- `TRAINING_DATASET_SELECTION`: Choose `\"random\"` or `\"top_n\"`.\n",
    "  - `\"random\"`: Randomly select masks from specified plates and wells.\n",
    "  - `\"top_n\"`: Select masks from tiles with the most instances. Useful for checking alignment with original images.\n",
    "- `TOP_N`: If using `\"top_n\"`, specify which ranked tile to use.\n",
    "\n",
    "**Other settings:**\n",
    "- `SCALE_BAR`: Scale bar length in pixels. If value exceeds image size, displays as dashed lines.\n",
    "- `RANDOM_SEED`: Random seed for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701c4c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DISPLAY_CHANNEL = [\"CDPK1\", \"DAPI\"]\n",
    "CHANNEL_COLORS = [\"r\", \"c\"]\n",
    "TRAINING_DATASET_SELECTION = \"random\"\n",
    "TOP_N = 0\n",
    "SCALE_BAR = 30\n",
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_KEYS = [\"plate\", \"well\", \"tile\", \"mask_label\"]\n",
    "\n",
    "try:\n",
    "    _STATE\n",
    "except NameError:\n",
    "    _STATE = {}\n",
    "\n",
    "_STATE.setdefault(\"rng\", np.random.default_rng(RANDOM_SEED))\n",
    "_STATE.setdefault(\"aligned_cache\", {})\n",
    "_STATE.setdefault(\"mask_cache\", {})\n",
    "_STATE.setdefault(\"parquet_cache\", {})\n",
    "_STATE.setdefault(\"mode\", str(CLASSIFY_BY_VACUOLE_OR_CELL).lower())\n",
    "_STATE.setdefault(\"container\", None)\n",
    "_STATE.setdefault(\"rows_state\", [])\n",
    "_STATE.setdefault(\"button\", None)\n",
    "_STATE.setdefault(\"status\", None)\n",
    "_STATE.setdefault(\"channel_header\", None)\n",
    "_STATE.setdefault(\"tile_order_df\", None)\n",
    "_STATE.setdefault(\"tile_idx\", 0)\n",
    "\n",
    "if \"manual_classified_df\" not in _STATE or _STATE[\"manual_classified_df\"] is None:\n",
    "    seed_df = globals().get(\"manual_classified_df\", None)\n",
    "    if isinstance(seed_df, pd.DataFrame) and not seed_df.empty:\n",
    "        _STATE[\"manual_classified_df\"] = seed_df.copy()\n",
    "    else:\n",
    "        _STATE[\"manual_classified_df\"] = None\n",
    "\n",
    "if \"manual_unclassified_df\" not in _STATE or _STATE[\"manual_unclassified_df\"] is None:\n",
    "    seed_unc = globals().get(\"manual_unclassified_df\", None)\n",
    "    if isinstance(seed_unc, pd.DataFrame) and not seed_unc.empty:\n",
    "        _STATE[\"manual_unclassified_df\"] = seed_unc.copy()\n",
    "    else:\n",
    "        _STATE[\"manual_unclassified_df\"] = None\n",
    "\n",
    "_STATE[\"manual_classified_df\"] = _ensure_mc_schema(_STATE[\"manual_classified_df\"], CLASS_TITLE, _KEYS)\n",
    "\n",
    "if _STATE[\"manual_unclassified_df\"] is None or _STATE[\"manual_unclassified_df\"].empty:\n",
    "    _STATE[\"manual_unclassified_df\"] = pd.DataFrame(columns=_KEYS)\n",
    "\n",
    "CHANNEL_NAMES = config[\"phenotype\"][\"channel_names\"]\n",
    "if len(set(DISPLAY_CHANNEL)) != len(DISPLAY_CHANNEL):\n",
    "    raise ValueError(\"DISPLAY_CHANNEL contains repeated channels. Each must be unique.\")\n",
    "missing = [ch for ch in DISPLAY_CHANNEL if ch not in CHANNEL_NAMES]\n",
    "if missing:\n",
    "    raise ValueError(f\"DISPLAY_CHANNEL not found in channel_names: {missing}\")\n",
    "CHANNEL_INDICES = [CHANNEL_NAMES.index(ch) for ch in DISPLAY_CHANNEL]\n",
    "\n",
    "resolved_colors = []\n",
    "for idx, ch in enumerate(DISPLAY_CHANNEL):\n",
    "    color_name = CHANNEL_COLORS[idx] if isinstance(CHANNEL_COLORS, list) and idx < len(CHANNEL_COLORS) else None\n",
    "    if color_name is None:\n",
    "        resolved_colors.append((\"gray\", (1.0, 1.0, 1.0)))\n",
    "    else:\n",
    "        try:\n",
    "            rgb = mcolors.to_rgb(color_name)\n",
    "            resolved_colors.append((\"rgb\", rgb))\n",
    "        except ValueError:\n",
    "            raise ValueError(f\"Invalid color '{color_name}' for channel '{ch}'. Use a valid matplotlib color name or hex.\")\n",
    "\n",
    "if _STATE.get(\"manual_classified_df\") is None:\n",
    "    _STATE[\"manual_classified_df\"] = _ensure_mc_schema(None, CLASS_TITLE, _KEYS)\n",
    "else:\n",
    "    _STATE[\"manual_classified_df\"] = _ensure_mc_schema(_STATE[\"manual_classified_df\"], CLASS_TITLE, _KEYS)\n",
    "\n",
    "if _STATE.get(\"manual_unclassified_df\") is None:\n",
    "    _STATE[\"manual_unclassified_df\"] = pd.DataFrame(columns=_KEYS)\n",
    "\n",
    "manual_classified_df = _STATE[\"manual_classified_df\"]\n",
    "manual_unclassified_df = _STATE[\"manual_unclassified_df\"]\n",
    "\n",
    "_render_next_batch(\n",
    "    state=_STATE,\n",
    "    DISPLAY_CHANNEL=DISPLAY_CHANNEL,\n",
    "    ADD_TRAINING_DATA=ADD_TRAINING_DATA,\n",
    "    keys=_KEYS,\n",
    "    CLASS_TITLE=CLASS_TITLE,\n",
    "    CLASSIFICATION=CLASSIFICATION,\n",
    "    RELABEL_CLASSIFICATIONS=RELABEL_CLASSIFICATIONS,\n",
    "    TRAINING_DATASET_SELECTION=TRAINING_DATASET_SELECTION,\n",
    "    BATCH_SIZE=BATCH_SIZE,\n",
    "    mask_summary_df=mask_summary_df,\n",
    "    mask_instances_df=mask_instances_df,\n",
    "    mask_instances_out_of_threshold_df=mask_instances_out_of_threshold_df,\n",
    "    OUT_OF_THRESHOLD_RANDOMIZER=OUT_OF_THRESHOLD_RANDOMIZER,\n",
    "    CHANNEL_INDICES=CHANNEL_INDICES,\n",
    "    PHENOTYPE_OUTPUT_FP=PHENOTYPE_OUTPUT_FP,\n",
    "    CHANNEL_NAMES=CHANNEL_NAMES,\n",
    "    MODE=CLASSIFY_BY_VACUOLE_OR_CELL,\n",
    "    RESOLVED_COLORS=resolved_colors,\n",
    "    SCALE_BAR=SCALE_BAR,\n",
    "    EXISTING_KEYS=_EXISTING_KEYS,\n",
    "    THRESHOLD_FEATURE_PRESENT=(THRESHOLD_FEATURE is not None),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9536480",
   "metadata": {},
   "outputs": [],
   "source": [
    "consolidated_df, training_dataset_out_path = consolidate_manual_classifications(\n",
    "    manual_classified_df=manual_classified_df,\n",
    "    class_title=CLASS_TITLE,\n",
    "    classify_mode=CLASSIFY_BY_VACUOLE_OR_CELL,\n",
    "    phenotype_output_fp=PHENOTYPE_OUTPUT_FP,\n",
    "    classifier_output_dir=CLASSIFIER_OUTPUT_DIR,\n",
    "    write=True,\n",
    "    verbose=True,\n",
    ")\n",
    "print(consolidated_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fsmx1wtjro9",
   "metadata": {},
   "source": [
    "## 2. Training\n",
    "\n",
    "Configure training parameters and train multiple model types to find the best classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lo11qz2r04k",
   "metadata": {},
   "source": [
    "### 2a. <font color='red'>SET PARAMETERS</font>: Training Dataset Configuration\n",
    "\n",
    "- `TRAINING_DATASET_FP`: Path to training dataset(s) in list format. Set to `None` to use the last classified dataset.\n",
    "- `METADATA_COLS`: Columns to treat as metadata (not features).\n",
    "- `TRAINING_CHANNELS`: Channels to include in training features.\n",
    "- `TRAINING_NAME`: Name identifier for this training run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0637c30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_DATASET_FP = None\n",
    "METADATA_COLS = ['vacuole_id', 'cell_id', 'plate', 'well', 'tile', 'parasite_count']\n",
    "TRAINING_CHANNELS = ['DAPI', 'CDPK1']\n",
    "TRAINING_NAME = \"paravacuole\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d938fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAINING_DATASET_FP is not None:\n",
    "    data = load_cellprofiler_data(TRAINING_DATASET_FP)\n",
    "else:\n",
    "    print(\"No training dataset provided, using last classified dataset\")\n",
    "    data = consolidated_df\n",
    "\n",
    "channel_names = config[\"phenotype\"][\"channel_names\"]\n",
    "feature_markers = {c: True for c in channel_names if c in TRAINING_CHANNELS}\n",
    "exclude_markers = [c for c in channel_names if c not in TRAINING_CHANNELS]\n",
    "\n",
    "print(f\"Class names: {CLASSIFICATION}\")\n",
    "print(f\"Class names to stored numeric values: {class_mapping}\")\n",
    "print(f\"Features to train upon: {feature_markers}\")\n",
    "print(f\"Features to exclude: {exclude_markers}\")\n",
    "print(f\"Target column: {CLASS_TITLE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bxbjez0fiof",
   "metadata": {},
   "source": [
    "### 2b. <font color='red'>SET PARAMETERS</font>: Filter Training Classes\n",
    "\n",
    "- `REMOVE_MASK_LABELS`: List of class labels to exclude from training (e.g., `[\"1 parasite\"]`). Set to `None` to keep all classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d83395b",
   "metadata": {},
   "outputs": [],
   "source": [
    "REMOVE_MASK_LABELS = None\n",
    "class_labels, filtered_class_mapping, class_id = filter_classes(CLASSIFICATION, class_mapping, REMOVE_MASK_LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7bb2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_configs = [\n",
    "    ('rf_standard', 'rf', 'standard', None),\n",
    "    ('svc_standard', 'svc', 'standard', None),\n",
    "    ('xgb_standard', 'xgb', 'standard', None),\n",
    "    ('lgb_standard', 'lgb', 'standard', None),\n",
    "    ('xgb_robust', 'xgb', 'robust', None),\n",
    "    ('xgb_minmax', 'xgb', 'minmax', None),\n",
    "    ('xgb_none', 'xgb', 'none', None),\n",
    "    ('xgb_none_var', 'xgb', 'none', {'enhance': True, 'remove_low_variance': True, 'remove_correlated': False, 'select_k_best': None}),\n",
    "    ('xgb_none_corr', 'xgb', 'none', {'enhance': True, 'remove_low_variance': False, 'remove_correlated': True, 'select_k_best': None}),\n",
    "    ('xgb_none_kbest100', 'xgb', 'none', {'enhance': True, 'remove_low_variance': False, 'remove_correlated': False, 'select_k_best': 100}),\n",
    "    ('xgb_none_combined', 'xgb', 'none', {'enhance': True, 'remove_low_variance': True, 'remove_correlated': True, 'select_k_best': 100}),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8cfcfe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_result = train_classifier_pipeline(\n",
    "    data=data,\n",
    "    class_title=CLASS_TITLE,\n",
    "    class_id=class_id,\n",
    "    class_labels=class_labels,\n",
    "    filtered_class_mapping=filtered_class_mapping,\n",
    "    metadata_cols=METADATA_COLS,\n",
    "    feature_markers=feature_markers,\n",
    "    exclude_markers=exclude_markers,\n",
    "    training_name=TRAINING_NAME,\n",
    "    model_configs=model_configs,\n",
    "    classifier_output_dir=CLASSIFIER_OUTPUT_DIR,\n",
    "    training_channels=TRAINING_CHANNELS,\n",
    "    verbose=True,\n",
    ")\n",
    "multiclass_df = pipeline_result['metrics_df']\n",
    "print(multiclass_df.head())\n",
    "\n",
    "run_dir = pipeline_result[\"dirs\"][\"run\"]\n",
    "print(f\"All outputs written to: {run_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabe3a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _to_list_of_str(value, fallback):\n",
    "    \"\"\"Normalize to a list of strings.\"\"\"\n",
    "    base = fallback if value is None else value\n",
    "    if isinstance(base, (list, tuple, set)):\n",
    "        return [str(x) for x in base]\n",
    "    return [str(base)]\n",
    "\n",
    "config[\"train_classifier\"] = {\n",
    "    \"classify_by\": str(CLASSIFY_BY_VACUOLE_OR_CELL),\n",
    "    \"class_title\": CLASS_TITLE,\n",
    "    \"classification\": list(CLASSIFICATION),\n",
    "    \"class_mapping\": class_mapping,\n",
    "    \"metadata_cols\": list(METADATA_COLS),\n",
    "    \"training_channels\": list(TRAINING_CHANNELS),\n",
    "    \"training_datasets\": _to_list_of_str(TRAINING_DATASET_FP, training_dataset_out_path),\n",
    "    \"channel_names\": list(config.get(\"phenotype\", {}).get(\"channel_names\", [])),\n",
    "    \"last_training_run\": str(run_dir),\n",
    "}\n",
    "\n",
    "with open(CONFIG_FILE_PATH, \"w\") as config_file:\n",
    "    config_file.write(\"\")\n",
    "    yaml.dump(config, config_file, default_flow_style=False)\n",
    "\n",
    "print(\"Updated config['train_classifier'] with current notebook parameters.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e892fe08",
   "metadata": {},
   "source": [
    "## 3. Selection\n",
    "\n",
    "Run the cells below to evaluate trained models and select the best one with an appropriate confidence threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f5a3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_RUN_DIR = \"run_20250904_144239\"\n",
    "TEST_PLATES = [\"1\", \"2\"]\n",
    "TEST_WELLS = [\"A1\", \"A2\", \"A3\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cu61r17fvrq",
   "metadata": {},
   "source": [
    "### 3a. <font color='red'>SET PARAMETERS</font>: Model Selection Settings\n",
    "\n",
    "- `MODEL_RUN_DIR`: Path to the model run directory to test (e.g., `\"run_20250903_114514\"`). Set to `None` to use the last training run.\n",
    "- `TEST_PLATES`: Plates to use for testing.\n",
    "- `TEST_WELLS`: Wells to use for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec55889",
   "metadata": {},
   "outputs": [],
   "source": [
    "plate = TEST_PLATES\n",
    "well = TEST_WELLS\n",
    "classify_by = config[\"train_classifier\"][\"classify_by\"]\n",
    "class_title = config[\"train_classifier\"][\"class_title\"]\n",
    "class_mapping = config[\"train_classifier\"][\"class_mapping\"]\n",
    "\n",
    "if MODEL_RUN_DIR is None:\n",
    "    CLASSIFIER_DIR_PATH = Path(config[\"train_classifier\"][\"last_training_run\"])\n",
    "else:\n",
    "    CLASSIFIER_DIR_PATH = Path(CLASSIFIER_OUTPUT_DIR) / \"classifier\" / str(MODEL_RUN_DIR)\n",
    "\n",
    "plates = plate if isinstance(plate, (list, tuple)) else [plate]\n",
    "wells = well if isinstance(well, (list, tuple)) else [well]\n",
    "plates = [str(p) for p in plates]\n",
    "wells = [str(w) for w in wells]\n",
    "\n",
    "parquet_dir = Path(PHENOTYPE_OUTPUT_FP) / \"parquets\"\n",
    "ctype = str(classify_by).lower()\n",
    "if ctype == \"cell\":\n",
    "    name_suffix = \"phenotype_cp.parquet\"\n",
    "elif ctype == \"vacuole\":\n",
    "    name_suffix = \"phenotype_vacuoles.parquet\"\n",
    "else:\n",
    "    raise ValueError(f\"Unsupported classify_by value: {classify_by}. Use 'cell' or 'vacuole'.\")\n",
    "\n",
    "master_phenotype_df, meta = build_master_phenotype_df(\n",
    "    plates=plates,\n",
    "    wells=wells,\n",
    "    name_suffix=name_suffix,\n",
    "    parquet_dir=parquet_dir,\n",
    "    display_fn=display,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "CONFIG_FOLDER_PATH = Path(\"config/\")\n",
    "METADATA_COLS_FP = CONFIG_FOLDER_PATH / \"cell_data_metadata_cols.tsv\"\n",
    "METADATA_COLS = config[\"train_classifier\"][\"metadata_cols\"]\n",
    "pd.Series(METADATA_COLS).to_csv(METADATA_COLS_FP, index=False, header=False, sep=\"\\t\")\n",
    "metadata, features = split_cell_data(master_phenotype_df, METADATA_COLS)\n",
    "print(metadata.shape, features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f27e7c8",
   "metadata": {},
   "source": [
    "## <font color='red'>Note</font>\n",
    "\n",
    "The cell below displays evaluation statistics for the selected model run. If no model was selected, the last trained model will be displayed. Based on the accuracy and F1 scores, select a model in the following cell. Your selection will be saved when you run the final cell of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefb0819",
   "metadata": {},
   "outputs": [],
   "source": [
    "_=display_pngs_in_plots_and_list_models(\n",
    "    CLASSIFIER_DIR_PATH, width=1200\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fx8xxowxgot",
   "metadata": {},
   "source": [
    "### 3b. <font color='red'>SET PARAMETERS</font>: Model and Montage Settings\n",
    "\n",
    "- `CLASSIFIER_MODEL`: Name of the model to use (e.g., `\"xgb_standard\"`). Set to `None` to use the best performing model.\n",
    "- `MONTAGE_CHANNEL`: Channel to use for montage images. Should be one of the channels used for training.\n",
    "- `COLLAPSE_COLS`: Columns to collapse on when creating classification summaries (e.g., `[\"plate\", \"well\"]`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3447663",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSIFIER_MODEL = None\n",
    "MONTAGE_CHANNEL = \"CDPK1\"\n",
    "COLLAPSE_COLS = [\"plate\", \"well\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6j21whyaq",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSIFIER_PATH, model_name = resolve_classifier_model_dill_path(CLASSIFIER_DIR_PATH, CLASSIFIER_MODEL)\n",
    "print(\"Selected model: \" + model_name)\n",
    "_ = show_model_evaluation_pngs(CLASSIFIER_DIR_PATH, model_name, width=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e3e050",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = CellClassifier.load(CLASSIFIER_PATH)\n",
    "classified_metadata, classified_features = classifier.classify_cells(metadata, features)\n",
    "\n",
    "print(classified_metadata.head())\n",
    "CELL_CLASSES = list(classified_metadata[class_title].unique())\n",
    "\n",
    "print(class_title + \" counts:\")\n",
    "print(classified_metadata[class_title].value_counts())\n",
    "\n",
    "print(\"\\n\" + class_title + \" confidences:\")\n",
    "classified_metadata[class_title + \"_confidence\"].hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f025uu8peqi",
   "metadata": {},
   "source": [
    "### 3c. <font color='red'>SET PARAMETERS</font>: Confidence Calibration\n",
    "\n",
    "- `CONFIDENCE_CORRECTION`: Set to `None` or `\"post-hoc\"` for post-hoc confidence correction.\n",
    "- `CALIBRATION_DATASET_FP`: Path to calibration dataset. Set to `None` to use the training dataset.\n",
    "- `CALIBRATION_METHOD`: Calibration method to use. Options are `\"isotonic\"` or `\"sigmoid\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04354afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIDENCE_CORRECTION = None\n",
    "CALIBRATION_DATASET_FP = None\n",
    "CALIBRATION_METHOD = \"isotonic\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0fa434",
   "metadata": {},
   "outputs": [],
   "source": [
    "if CALIBRATION_DATASET_FP is not None:\n",
    "    manual_labeled_data = load_cellprofiler_data(CALIBRATION_DATASET_FP)\n",
    "else:\n",
    "    print(\"No calibration dataset provided, using training dataset\")\n",
    "    CALIBRATION_DATASET_FP = config[\"train_classifier\"][\"training_datasets\"]\n",
    "    if CALIBRATION_DATASET_FP is None or len(CALIBRATION_DATASET_FP) == 0:\n",
    "        raise ValueError(\"No calibration dataset provided and no training dataset found in config.\")\n",
    "    manual_labeled_data = load_cellprofiler_data(CALIBRATION_DATASET_FP)\n",
    "\n",
    "classified_metadata, meta = calibrate_confidence(\n",
    "    master_phenotype_df=master_phenotype_df,\n",
    "    classified_metadata=classified_metadata,\n",
    "    manual_labeled_data=manual_labeled_data,\n",
    "    classify_by=classify_by,\n",
    "    class_title=class_title,\n",
    "    classifier_path=CLASSIFIER_PATH,\n",
    "    confidence_correction=CONFIDENCE_CORRECTION,\n",
    "    calibration_method=CALIBRATION_METHOD,\n",
    "    test_plate=plates,\n",
    "    test_well=wells,\n",
    "    min_samples_isotonic=50,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "print(meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debfbc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes, montages, titles, ORDERED_CLASSES, summary_df = build_montages_and_summary(\n",
    "    master_phenotype_df=master_phenotype_df,\n",
    "    classified_metadata=classified_metadata,\n",
    "    classify_by=classify_by,\n",
    "    class_mapping=class_mapping,\n",
    "    class_title=class_title,\n",
    "    root_fp=ROOT_FP,\n",
    "    channels=config[\"phenotype\"][\"channel_names\"],\n",
    "    montage_channel=MONTAGE_CHANNEL,\n",
    "    collapse_cols=COLLAPSE_COLS,\n",
    "    verbose=True,\n",
    "    show_figure=True,\n",
    "    display_fn=display,  # optional\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da866fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "DISPLAY_CHANNEL = [\"CDPK1\", \"DAPI\"]\n",
    "CHANNEL_COLORS = [\"r\", \"c\"]\n",
    "SCALE_BAR = 30\n",
    "MINIMUM_DIFFERENCE = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313b2214",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = launch_rankline_ui(\n",
    "    classified_metadata=classified_metadata,\n",
    "    class_title=class_title,\n",
    "    classify_by=classify_by,\n",
    "    class_mapping=class_mapping,\n",
    "    phenotype_output_fp=PHENOTYPE_OUTPUT_FP,\n",
    "    channel_names=list(config[\"phenotype\"][\"channel_names\"]),\n",
    "    display_channels=DISPLAY_CHANNEL,\n",
    "    channel_colors=CHANNEL_COLORS,\n",
    "    test_plate=plates,\n",
    "    test_well=wells,\n",
    "    scale_bar_px=SCALE_BAR,\n",
    "    minimum_difference=MINIMUM_DIFFERENCE,\n",
    "    thumbnail_px=150,\n",
    "    auto_display=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c49e1fc",
   "metadata": {},
   "source": [
    "## Add classifier parameters to config file\n",
    "\n",
    "Running the cells below will save your selected model and confidence threshold to the config file for use in the aggregate pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1abb87f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIDENCE_THRESHOLD = 0.59\n",
    "print(\"Currently applied model: \" + model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612e94a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "config[\"train_classifier\"].update({\n",
    "    \"CLASSIFIER_MODEL\": str(CLASSIFIER_MODEL),\n",
    "    \"CLASSIFIER_PATH\": str(CLASSIFIER_PATH),\n",
    "    \"CONFIDENCE_THRESHOLD\": CONFIDENCE_THRESHOLD,\n",
    "})\n",
    "\n",
    "with open(CONFIG_FILE_PATH, \"w\") as config_file:\n",
    "    config_file.write(\"\")\n",
    "    yaml.safe_dump(config, config_file, sort_keys=False, default_flow_style=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brieflow_SCREEN_NAME",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

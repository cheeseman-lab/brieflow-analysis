{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure Phenotype Parameters\n",
    "\n",
    "This notebook should be used as a test for ensuring correct phenotype image loading and processing before running phenotype module.\n",
    "Cells marked with <font color='red'>SET PARAMETERS</font> contain crucial variables that need to be set according to your specific experimental setup and data organization.\n",
    "Please review and modify these variables as needed before proceeding with the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>SET PARAMETERS</font>\n",
    "\n",
    "### Fixed parameters for phenotype processing\n",
    "\n",
    "- `CONFIG_FILE_PATH`: Path to a Brieflow config file used during processing. Absolute or relative to where workflows are run from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_FILE_PATH = \"config/config.yml\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import yaml\n",
    "import numpy as np\n",
    "from tifffile import imread\n",
    "import matplotlib.pyplot as plt\n",
    "from microfilm.microplot import Microimage\n",
    "from skimage import measure\n",
    "\n",
    "from lib.shared.configuration_utils import (\n",
    "    CONFIG_FILE_HEADER,\n",
    "    create_micropanel,\n",
    "    random_cmap,\n",
    "    image_segmentation_annotations,\n",
    "    convert_tuples_to_lists,\n",
    ")\n",
    "from lib.shared.file_utils import get_filename\n",
    "from lib.shared.illumination_correction import apply_ic_field\n",
    "from lib.phenotype.align_channels import align_phenotype_channels, visualize_phenotype_alignment\n",
    "from lib.shared.align import apply_custom_offsets\n",
    "from lib.phenotype.identify_cytoplasm_cellpose import (\n",
    "    identify_cytoplasm_cellpose,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>SET PARAMETERS</font>\n",
    "\n",
    "### Parameters for testing phenotype processing\n",
    "\n",
    "- `TEST_PLATE`, `TEST_WELL`, `TEST_TILE`: Plate/well/tile combination used for configuring parameters in this notebook.\n",
    "\n",
    "### Channels\n",
    "- `CHANNEL_NAMES`: A list of names for each channel in your phenotyping image. These names will be used in the output data frame to label the features extracted from each channel.\n",
    "- `CHANNEL_CMAPS`: A list of color maps to use when showing channel microimages. These need to be a Matplotlib or microfilm colormap. We recommend using: `[\"pure_red\", \"pure_green\", \"pure_blue\", \"pure_cyan\", \"pure_magenta\", \"pure_yellow\"]`.\n",
    "\n",
    "### Feature Extraction\n",
    "\n",
    "- `FOCI_CHANNEL`: Name of the channel used for foci detection (e.g., \"GH2AX\", \"DAPI\"). The channel index will be automatically derived from this name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for testing\n",
    "TEST_PLATE = None\n",
    "TEST_WELL = None\n",
    "TEST_TILE = None\n",
    "WILDCARDS = dict(well=TEST_WELL, tile=TEST_TILE)\n",
    "\n",
    "CHANNEL_NAMES = None\n",
    "CHANNEL_CMAPS = None\n",
    "\n",
    "# Parameters for feature extraction\n",
    "FOCI_CHANNEL = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load config file\n",
    "with open(CONFIG_FILE_PATH, \"r\") as config_file:\n",
    "    config = yaml.safe_load(config_file)\n",
    "\n",
    "# Load test image data\n",
    "print(\"Loading test image...\")\n",
    "ROOT_FP = Path(config[\"all\"][\"root_fp\"])\n",
    "PREPROCESS_FP = ROOT_FP / \"preprocess\"\n",
    "phenotype_test_image_path = str(\n",
    "    PREPROCESS_FP\n",
    "    / \"images\"\n",
    "    / \"phenotype\"\n",
    "    / get_filename(\n",
    "        {\"plate\": TEST_PLATE, \"well\": TEST_WELL, \"tile\": TEST_TILE},\n",
    "        \"image\",\n",
    "        \"tiff\",\n",
    "    )\n",
    ")\n",
    "phenotype_test_image = imread(phenotype_test_image_path)\n",
    "\n",
    "print(\"Applying illumination correction...\")\n",
    "# Read the illumination correction file\n",
    "ic_field_path = str(\n",
    "    PREPROCESS_FP\n",
    "    / \"ic_fields\"\n",
    "    / \"phenotype\"\n",
    "    / get_filename({\"plate\": TEST_PLATE, \"well\": TEST_WELL}, \"ic_field\", \"tiff\")\n",
    ")\n",
    "ic_field = imread(ic_field_path)\n",
    "\n",
    "# Apply illumination correction\n",
    "corrected_image = apply_ic_field(phenotype_test_image, correction=ic_field)\n",
    "\n",
    "# Create and display micropanel of corrected images\n",
    "print(\"Example corrected image:\")\n",
    "corrected_microimages = [\n",
    "    Microimage(\n",
    "        corrected_image[i], channel_names=CHANNEL_NAMES[i], cmaps=CHANNEL_CMAPS[i]\n",
    "    )\n",
    "    for i in range(corrected_image.shape[0])\n",
    "]\n",
    "corrected_panel = create_micropanel(corrected_microimages, add_channel_label=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>SET PARAMETERS</font>\n",
    "\n",
    "### Aligning (optional)\n",
    "\n",
    "- `ALIGN`: Whether to conduct alignment. This is suggested **unless** each image is captured with each channel consecutively. \n",
    "- `TARGET`: Name of the channel that other channels will be aligned to.\n",
    "- `SOURCE`: Name of the channel to align with the target.\n",
    "- `RIDERS`: Additional channel indices that should follow the same alignment as the source channel.\n",
    "- `REMOVE_CHANNEL`: Specifies whether to remove channels after alignment. In the case of duplicate channels that are used to align the image, should be set to `source`.\n",
    "- `UPSAMPLE_FACTOR`: Subpixel alignment precision factor (default: 2). Higher values provide more precise alignment but increase processing time.\n",
    "- `WINDOW`: Size of the region used for alignment calculation (default: 2). Higher values use a smaller centered region of the image.\n",
    "\n",
    "**Note for multi-round phenotyping**: For more than 2 imaging cycles (e.g., 3 rounds with repeated DAPI channels), perform sequential alignments by calling `align_phenotype_channels` multiple times in the next cell. Each round should align its channels to the same reference (e.g., the first DAPI).\n",
    "\n",
    "### Custom Alignment (optional)\n",
    "\n",
    "- `CUSTOM_CHANNEL_OFFSETS`: Dict mapping channel names to their (y, x) pixel offsets. Can be used independently or in combination with standard alignment for fine-tuning channel registration. Example: `{\"DAPI\": (5, 10), \"AF750\": (3, -2)}` shifts DAPI by 5 pixels up and 10 left, AF750 by 3 up and 2 right. Channel names must match those in `CHANNEL_NAMES`. Offset directions: +y = up, -y = down, +x = left, -x = right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set alignment parameters\n",
    "ALIGN = None\n",
    "TARGET = None\n",
    "SOURCE = None\n",
    "RIDERS = None\n",
    "REMOVE_CHANNEL = None\n",
    "UPSAMPLE_FACTOR = 2\n",
    "WINDOW = 2\n",
    "\n",
    "# Set custom channel offsets (use channel names, not indices)\n",
    "CUSTOM_CHANNEL_OFFSETS = None  # Example: {\"DAPI\": (5, 10), \"AF750\": (3, -2)}\n",
    "\n",
    "# Derive alignment indexes\n",
    "if ALIGN:\n",
    "    TARGET_INDEX = CHANNEL_NAMES.index(TARGET)\n",
    "    SOURCE_INDEX = CHANNEL_NAMES.index(SOURCE)\n",
    "    RIDER_INDEXES = [CHANNEL_NAMES.index(r) for r in RIDERS]\n",
    "\n",
    "# Derive custom alignment indexes from channel names\n",
    "if CUSTOM_CHANNEL_OFFSETS:\n",
    "    CUSTOM_CHANNEL_OFFSETS_INDEXED = {\n",
    "        CHANNEL_NAMES.index(name): offset \n",
    "        for name, offset in CUSTOM_CHANNEL_OFFSETS.items()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with the corrected image\n",
    "aligned_image = corrected_image.copy()\n",
    "\n",
    "# Apply custom offsets \n",
    "if CUSTOM_CHANNEL_OFFSETS:\n",
    "    print(f\"Custom offsets: {CUSTOM_CHANNEL_OFFSETS_INDEXED}\")\n",
    "    aligned_image = apply_custom_offsets(\n",
    "        aligned_image,\n",
    "        offsets_dict=CUSTOM_CHANNEL_OFFSETS_INDEXED\n",
    "    )\n",
    "\n",
    "# Apply automatic alignment\n",
    "if ALIGN:\n",
    "    aligned_image = align_phenotype_channels(\n",
    "        aligned_image,\n",
    "        target=TARGET_INDEX,\n",
    "        source=SOURCE_INDEX,\n",
    "        riders=RIDER_INDEXES,\n",
    "        remove_channel=REMOVE_CHANNEL,\n",
    "        upsample_factor=UPSAMPLE_FACTOR,\n",
    "        window=WINDOW,\n",
    "        verbose=True,\n",
    "    )\n",
    "    # Automatically remove channels based on REMOVE_CHANNEL\n",
    "    if REMOVE_CHANNEL == \"source\":\n",
    "        remove_index = CHANNEL_NAMES.index(SOURCE)\n",
    "        CHANNEL_NAMES.pop(remove_index)\n",
    "        CHANNEL_CMAPS.pop(remove_index)\n",
    "    elif REMOVE_CHANNEL == \"target\":\n",
    "        remove_index = CHANNEL_NAMES.index(TARGET)\n",
    "        CHANNEL_NAMES.pop(remove_index)\n",
    "        CHANNEL_CMAPS.pop(remove_index)\n",
    "    elif REMOVE_CHANNEL == \"riders\":\n",
    "        # Remove riders in reverse order to maintain correct indices\n",
    "        for rider in reversed(RIDERS):\n",
    "            remove_index = CHANNEL_NAMES.index(rider)\n",
    "            CHANNEL_NAMES.pop(remove_index)\n",
    "            CHANNEL_CMAPS.pop(remove_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Alignment Quality (Optional)\n",
    "\n",
    "Visualize channel alignment across 16 locations in the image. The first channel (DAPI) is shown in grayscale with the remaining 3 channels as an RGB overlay. You may want to consider removing channels for a first pass if you want to visualize alignment between different rounds.\n",
    "\n",
    "- `VIZ_CHANNELS`: List of exactly 4 channel names to visualize (1st=grayscale base, 2nd-4th=RGB overlay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set channels to visualize (first=grayscale, remaining 3=RGB overlay)\n",
    "VIZ_CHANNELS = None\n",
    "\n",
    "if VIZ_CHANNELS is not None:\n",
    "    print(\"Visualizing alignment across 16 locations...\")\n",
    "    fig = visualize_phenotype_alignment(\n",
    "        aligned_image,\n",
    "        channel_names=CHANNEL_NAMES,\n",
    "        viz_channels=VIZ_CHANNELS,\n",
    "        crop_size=300\n",
    "    )\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Skipping visualization (VIZ_CHANNELS not set)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>SET PARAMETERS</font>\n",
    "\n",
    "### Segmentation\n",
    "\n",
    "**IMPORTANT: GPU Recommendation for CPSAM**\n",
    "If testing the CPSAM model (`CELLPOSE_MODEL=\"cpsam\"`), we strongly recommend:\n",
    "- Using a GPU-enabled machine (`GPU=True`)\n",
    "- Allocating sufficient time (segmentation can take 30+ minutes per tile)\n",
    "- Consider running this notebook in a GPU-enabled environment or testing on a smaller region\n",
    "\n",
    "#### Select Segmentation Method\n",
    "- `SEGMENTATION_METHOD`: Choose from \"cellpose\" or \"stardist\" for cell segmentation.\n",
    "\n",
    "#### Cellpose Parameters (if using \"cellpose\")\n",
    "- `CELLPOSE_MODEL`: CellPose model to use. Options: \"cyto3\" (default), \"cyto2\", \"cyto\", or \"cpsam\" (requires Cellpose 4.x).\n",
    "- `CELL_FLOW_THRESHOLD` & `NUCLEI_FLOW_THRESHOLD`: Flow threshold for Cellpose segmentation. Default is 0.4.\n",
    "- `CELL_CELLPROB_THRESHOLD` & `NUCLEI_CELLPROB_THRESHOLD`: Cell probability threshold for Cellpose. Default is 0.\n",
    "- `HELPER_INDEX`: (Optional) Index of additional channel to help with CPSAM segmentation. Only used with `CELLPOSE_MODEL=\"cpsam\"`. Default is None.\n",
    "- Note: For Cellpose 3.x models (cyto3, cyto2), nuclei and cell diameters will be estimated automatically. For CPSAM (Cellpose 4.x), diameters can be left as None and will be estimated from initial segmentation results.\n",
    "\n",
    "#### StarDist Parameters (if using \"stardist\")\n",
    "- `STARDIST_MODEL`: StarDist model type. Default is \"2D_versatile_fluo\".\n",
    "- `CELL_PROB_THRESHOLD` & `NUCLEI_PROB_THRESHOLD`: Probability threshold for segmentation. Default is 0.479071.\n",
    "- `CELL_NMS_THRESHOLD` & `NUCLEI_NMS_THRESHOLD`: Non-maximum suppression threshold. Default is 0.3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common parameters\n",
    "CYTO_CHANNEL = None\n",
    "GPU = False\n",
    "RECONCILE = \"contained_in_cells\"\n",
    "DAPI_INDEX = CHANNEL_NAMES.index(\"DAPI\")\n",
    "CYTO_INDEX = CHANNEL_NAMES.index(CYTO_CHANNEL)\n",
    "\n",
    "# Select segmentation method\n",
    "SEGMENTATION_METHOD = \"cellpose\"\n",
    "\n",
    "if SEGMENTATION_METHOD == \"cellpose\":\n",
    "    # Parameters for CellPose method\n",
    "    CELLPOSE_MODEL = \"cyto3\"\n",
    "    NUCLEI_FLOW_THRESHOLD = 0.4\n",
    "    NUCLEI_CELLPROB_THRESHOLD = 0.0\n",
    "    CELL_FLOW_THRESHOLD = 1\n",
    "    CELL_CELLPROB_THRESHOLD = 0\n",
    "    HELPER_INDEX = None  # Optional: channel index to help with CPSAM segmentation\n",
    "\n",
    "    # Only estimate diameters for non-CPSAM models\n",
    "    if CELLPOSE_MODEL != \"cpsam\":\n",
    "        from lib.shared.segment_cellpose import estimate_diameters\n",
    "        print(\"Estimating optimal cell and nuclei diameters...\")\n",
    "        NUCLEI_DIAMETER, CELL_DIAMETER = estimate_diameters(\n",
    "            aligned_image,\n",
    "            dapi_index=DAPI_INDEX,\n",
    "            cyto_index=CYTO_INDEX,\n",
    "            cellpose_model=CELLPOSE_MODEL,\n",
    "        )\n",
    "    else:\n",
    "        print(\"CPSAM model selected. Initial diameters set to None.\")\n",
    "        print(\"Note: Diameters will be estimated automatically from segmentation results in the next cell.\")\n",
    "        NUCLEI_DIAMETER = None  # Will be estimated from segmentation\n",
    "        CELL_DIAMETER = None    # Will be estimated from segmentation\n",
    "\n",
    "elif SEGMENTATION_METHOD == \"stardist\":\n",
    "    # Parameters for StarDist method\n",
    "    STARDIST_MODEL = \"2D_versatile_fluo\"\n",
    "    NUCLEI_PROB_THRESHOLD = 0.479071\n",
    "    NUCLEI_NMS_THRESHOLD = 0.3\n",
    "    CELL_PROB_THRESHOLD = 0.479071\n",
    "    CELL_NMS_THRESHOLD = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Segmenting image with {SEGMENTATION_METHOD}...\")\n",
    "\n",
    "if SEGMENTATION_METHOD == \"cellpose\":\n",
    "    from lib.shared.segment_cellpose import segment_cellpose\n",
    "    nuclei, cells = segment_cellpose(\n",
    "        aligned_image,\n",
    "        dapi_index=DAPI_INDEX,\n",
    "        cyto_index=CYTO_INDEX,\n",
    "        nuclei_diameter=NUCLEI_DIAMETER,\n",
    "        cell_diameter=CELL_DIAMETER,\n",
    "        cellpose_kwargs=dict(\n",
    "            nuclei_flow_threshold=NUCLEI_FLOW_THRESHOLD,\n",
    "            nuclei_cellprob_threshold=NUCLEI_CELLPROB_THRESHOLD,\n",
    "            cell_flow_threshold=CELL_FLOW_THRESHOLD,\n",
    "            cell_cellprob_threshold=CELL_CELLPROB_THRESHOLD,\n",
    "        ),\n",
    "        cellpose_model=CELLPOSE_MODEL,\n",
    "        helper_index=HELPER_INDEX,\n",
    "        gpu=GPU,\n",
    "        reconcile=RECONCILE,\n",
    "    )\n",
    "\n",
    "elif SEGMENTATION_METHOD == \"stardist\":\n",
    "    from lib.shared.segment_stardist import segment_stardist\n",
    "    nuclei, cells = segment_stardist(\n",
    "        aligned_image,\n",
    "        dapi_index=DAPI_INDEX,\n",
    "        cyto_index=CYTO_INDEX,\n",
    "        model_type=STARDIST_MODEL,\n",
    "        stardist_kwargs=dict(\n",
    "            nuclei_prob_threshold=NUCLEI_PROB_THRESHOLD,\n",
    "            nuclei_nms_threshold=NUCLEI_NMS_THRESHOLD,\n",
    "            cell_prob_threshold=CELL_PROB_THRESHOLD,\n",
    "            cell_nms_threshold=CELL_NMS_THRESHOLD,\n",
    "        ),\n",
    "        gpu=GPU,\n",
    "        reconcile=RECONCILE,\n",
    "    )\n",
    "\n",
    "# Create and display micropanel of nuclei segmentation\n",
    "print(\"Example microplots for DAPI channel and nuclei segmentation:\")\n",
    "nuclei_cmap = random_cmap(num_colors=len(np.unique(nuclei)))\n",
    "nuclei_seg_microimages = [\n",
    "    Microimage(\n",
    "        aligned_image[DAPI_INDEX],\n",
    "        channel_names=\"DAPI\",\n",
    "        cmaps=CHANNEL_CMAPS[DAPI_INDEX],\n",
    "    ),\n",
    "    Microimage(nuclei, cmaps=nuclei_cmap, channel_names=\"Nuclei\"),\n",
    "]\n",
    "nuclei_seg_panel = create_micropanel(nuclei_seg_microimages, add_channel_label=True)\n",
    "plt.show()\n",
    "\n",
    "# Create and display micropanel of segmented cells\n",
    "print(\"Example microplots for merged channels and cells segmentation:\")\n",
    "cells_cmap = random_cmap(num_colors=len(np.unique(cells)))\n",
    "cells_seg_microimages = [\n",
    "    Microimage(\n",
    "        aligned_image,\n",
    "        channel_names=\"Merged\",\n",
    "        cmaps=CHANNEL_CMAPS,\n",
    "    ),\n",
    "    Microimage(cells, cmaps=cells_cmap, channel_names=\"Cells\"),\n",
    "]\n",
    "cells_seg_panel = create_micropanel(cells_seg_microimages, add_channel_label=True)\n",
    "plt.show()\n",
    "\n",
    "# Create and display micropanel of annotated phenotype data\n",
    "print(\"Example microplot for phenotype data annotated with segmentation:\")\n",
    "annotated_data = image_segmentation_annotations(aligned_image, nuclei, cells)\n",
    "annotated_microimage = [\n",
    "    Microimage(\n",
    "        annotated_data, channel_names=\"Merged\", cmaps=CHANNEL_CMAPS + [\"pure_cyan\"]\n",
    "    )\n",
    "]\n",
    "annotated_panel = create_micropanel(\n",
    "    annotated_microimage, num_cols=1, figscaling=10, add_channel_label=False\n",
    ")\n",
    "plt.show()\n",
    "\n",
    "# Create and display micropanel of cytoplasms\n",
    "print(\"Example microplots for cytoplasms relative to nuclei:\")\n",
    "cytoplasms = identify_cytoplasm_cellpose(nuclei, cells)\n",
    "cytoplasms_cmap = random_cmap(num_colors=len(np.unique(cytoplasms)))\n",
    "cytoplasms_microimages = [\n",
    "    Microimage(nuclei, cmaps=nuclei_cmap, channel_names=\"Nuclei\"),\n",
    "    Microimage(cytoplasms, cmaps=cytoplasms_cmap, channel_names=\"Cytoplasms\"),\n",
    "]\n",
    "cytoplasms_panel = create_micropanel(cytoplasms_microimages, add_channel_label=True)\n",
    "plt.show()\n",
    "\n",
    "if SEGMENTATION_METHOD == \"cellpose\" and CELLPOSE_MODEL == \"cpsam\":\n",
    "    from skimage.measure import regionprops\n",
    "    import numpy as np\n",
    "\n",
    "    # Calculate nuclei diameters\n",
    "    nuclei_props = regionprops(nuclei)\n",
    "    nuclei_diameters = [prop.equivalent_diameter for prop in nuclei_props]\n",
    "    estimated_nuclei_diameter = np.mean(nuclei_diameters)\n",
    "    print(f\"Nuclei - Average diameter: {estimated_nuclei_diameter:.2f} pixels\")\n",
    "\n",
    "    # Calculate cell diameters  \n",
    "    cells_props = regionprops(cells)\n",
    "    cells_diameters = [prop.equivalent_diameter for prop in cells_props]\n",
    "    estimated_cell_diameter = np.mean(cells_diameters)\n",
    "    print(f\"Cells - Average diameter: {estimated_cell_diameter:.2f} pixels\")\n",
    "    \n",
    "    # Update the diameter variables for config\n",
    "    NUCLEI_DIAMETER = estimated_nuclei_diameter\n",
    "    CELL_DIAMETER = estimated_cell_diameter\n",
    "    print(f\"\\nUpdated NUCLEI_DIAMETER to {NUCLEI_DIAMETER:.2f} pixels\")\n",
    "    print(f\"Updated CELL_DIAMETER to {CELL_DIAMETER:.2f} pixels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: You may want to adjust these parameters and run segmentation tests if you feel you are capturing too little or too much area for the masks. For cellpose, the nuclei and cell diameters will be automatically estimated, but can be manually adjusted if needed. You manually can set `NUCLEI_DIAMETER` and `CELL_DIAMETER` and rerun the above blocks as many times as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>SET PARAMETERS</font>\n",
    "\n",
    "### Feature extraction\n",
    "\n",
    "- `CP_METHOD`: Methodology for phenotype feature extraction.  \n",
    "    - `cp_multichannel`: Use emulated code from original _Feldman et. al. 2019_ to extract CellProfiler-like features.\n",
    "    - `cp_measure`: Use Pythonic version of [CellProfiler](https://github.com/afermg/cp_measure) directly from Imaging Platform. Still in development, may run slowly in Jupyter notebook for testing purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CP_METHOD = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Extracting phenotype features:\")\n",
    "\n",
    "# Compute foci channel index from channel name\n",
    "if FOCI_CHANNEL:\n",
    "    FOCI_CHANNEL_INDEX = CHANNEL_NAMES.index(FOCI_CHANNEL)\n",
    "else:\n",
    "    FOCI_CHANNEL_INDEX = None\n",
    "\n",
    "if CP_METHOD == \"cp_measure\":\n",
    "    from lib.phenotype.extract_phenotype_cp_measure import extract_phenotype_cp_measure\n",
    "    # Extract features using cp_measure\n",
    "    phenotype_cp = extract_phenotype_cp_measure(\n",
    "        aligned_image,\n",
    "        nuclei=nuclei,\n",
    "        cells=cells,\n",
    "        cytoplasms=cytoplasms,\n",
    "        channel_names=CHANNEL_NAMES,\n",
    "    )\n",
    "else:\n",
    "    from lib.phenotype.extract_phenotype_cp_multichannel import (\n",
    "        extract_phenotype_cp_multichannel,\n",
    "    )\n",
    "    # Extract features using CellProfiler emulator\n",
    "    phenotype_cp = extract_phenotype_cp_multichannel(\n",
    "        aligned_image,\n",
    "        nuclei=nuclei,\n",
    "        cells=cells,\n",
    "        wildcards=WILDCARDS,\n",
    "        cytoplasms=cytoplasms,\n",
    "        foci_channel=FOCI_CHANNEL_INDEX,\n",
    "        channel_names=CHANNEL_NAMES,\n",
    "    )\n",
    "\n",
    "phenotype_cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove channel names from feature names\n",
    "def remove_channel_name(feature, channels):\n",
    "    for channel in channels:\n",
    "        feature = feature.replace(f\"_{channel}\", \"\")\n",
    "    return feature\n",
    "\n",
    "\n",
    "# Remove label, well, tile and isolate remaining feature names\n",
    "filtered_features = [\n",
    "    feature\n",
    "    for feature in phenotype_cp.columns.tolist()\n",
    "    if feature not in [\"label\", \"well\", \"tile\"]\n",
    "]\n",
    "\n",
    "# Apply the function to remove channel names\n",
    "feature_types = [\n",
    "    remove_channel_name(feature, CHANNEL_NAMES) for feature in filtered_features\n",
    "]\n",
    "\n",
    "# Get unique feature types\n",
    "unique_feature_types = sorted(set(feature_types))\n",
    "\n",
    "print(\"Unique feature types:\")\n",
    "unique_feature_types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>SET PARAMETERS</font>\n",
    "\n",
    "### Secondary object detection (optional)\n",
    "\n",
    "- `SECOND_OBJ_DETECTION`: Whether to perform secondary object detection (e.g., intracellular pathogen, organelles).\n",
    "- `SECOND_OBJ_CHANNEL`: Name of the channel used for secondary object detection.\n",
    "- `SECOND_OBJ_METHOD`: Segmentation method to use. Options:\n",
    "  - `\"threshold\"`: Traditional thresholding-based approach\n",
    "  - `\"cellpose\"`: ML-based segmentation using Cellpose\n",
    "  - `\"stardist\"`: ML-based segmentation using StarDist\n",
    "\n",
    "#### Size Filtering (applies to all methods)\n",
    "- `SIZE_FILTER_METHOD`: Method for size filtering. Options:\n",
    "  - `\"feret\"`: Use Feret diameters (min and max widths of rotated bounding box).\n",
    "  - `\"area\"`: Use pixel area.\n",
    "- `SECOND_OBJ_MIN_SIZE`: Minimum size for valid secondary objects. Interpreted as Feret diameter or area depending on `SIZE_FILTER_METHOD`.\n",
    "- `SECOND_OBJ_MAX_SIZE`: Maximum size for valid secondary objects.\n",
    "\n",
    "\n",
    "#### Cell Association (applies to all methods)\n",
    "- `MAX_OBJECTS_PER_CELL`: Maximum secondary objects allowed per cell.\n",
    "- `OVERLAP_THRESHOLD`: Minimum overlap ratio to associate object with cell.\n",
    "- `MAX_TOTAL_OBJECTS`: Failsafe limit on detected objects. Returns empty results if exceeded to avoid processing over-segmented images.\n",
    "\n",
    "#### Cellpose Parameters (if `SECOND_OBJ_METHOD=\"cellpose\"`)\n",
    "- `SECOND_OBJ_CELLPOSE_MODEL`: Cellpose model type. Options: `\"cyto3\"` (default), `\"cyto2\"`, `\"cyto\"`, `\"nuclei\"`, etc.\n",
    "- `SECOND_OBJ_DIAMETER`: Expected diameter of objects in pixels. If `None`, will be estimated automatically.\n",
    "- `SECOND_OBJ_FLOW_THRESHOLD`: Flow error threshold for Cellpose segmentation (default: 0.4).\n",
    "- `SECOND_OBJ_CELLPROB_THRESHOLD`: Cell probability threshold for Cellpose (default: 0.0).\n",
    "\n",
    "#### StarDist Parameters (if `SECOND_OBJ_METHOD=\"stardist\"`)\n",
    "- `SECOND_OBJ_STARDIST_MODEL`: StarDist pretrained model name (default: `\"2D_versatile_fluo\"`).\n",
    "- `SECOND_OBJ_PROB_THRESHOLD`: Probability threshold for object detection (default: 0.5).\n",
    "- `SECOND_OBJ_NMS_THRESHOLD`: Non-maximum suppression threshold (default: 0.4).\n",
    "\n",
    "#### Threshold Method Parameters (if `SECOND_OBJ_METHOD=\"threshold\"`)\n",
    "\n",
    "**Pre-processing**\n",
    "- `THRESHOLD_SMOOTHING_SCALE`: Sigma for Gaussian smoothing before thresholding.\n",
    "- `THRESHOLD_METHOD`: Thresholding method to use. Options:\n",
    "  - `\"otsu_two_peak\"`: Standard 2-class Otsu thresholding.\n",
    "  - `\"otsu_three_peak_mid_bg\"`: 3-class Otsu, keeps only highest intensity class.\n",
    "  - `\"otsu_three_peak_mid_fg\"`: 3-class Otsu, keeps middle and high intensity classes.\n",
    "  - `\"min_cross_entropy\"`: Minimum cross entropy (Li) thresholding.\n",
    "- `USE_MORPHOLOGICAL_OPENING`: Apply morphological opening to separate weakly connected objects.\n",
    "- `OPENING_DISK_RADIUS`: Radius of disk structuring element for morphological opening.\n",
    "- `FILL_HOLES`: When to fill holes in segmented objects. Options:\n",
    "  - `\"threshold\"`: Fill holes only after thresholding (before declumping)\n",
    "  - `\"declump\"`: Fill holes only after declumping (per-label filling)\n",
    "  - `\"both\"`: Fill holes after both thresholding and declumping (recommended)\n",
    "  - `\"none\"`: Do not fill holes at any stage\n",
    "\n",
    "**Declumping Method**\n",
    "- `DECLUMP_METHOD`: Method for separating clumped objects. Options:\n",
    "  - `\"none\"`: No declumping.\n",
    "  - `\"shape\"`: Distance transform peaks (radial distance).\n",
    "  - `\"intensity\"`: Local intensity maxima.\n",
    "  - `\"shape_intensity\"`: Combined distance + intensity peaks.\n",
    "- `DECLUMP_MODE`: Watershed segmentation mode. Options:\n",
    "  - `\"watershed\"`: Standard watershed from markers\n",
    "  - `\"propagate\"`: Distance propagation variant\n",
    "  - `\"none\"`: Use markers only without watershed\n",
    "\n",
    "**Seed Detection**\n",
    "- `SUPPRESS_LOCAL_MAXIMA`: Minimum spacing between seed points in pixels. Controls spatial separation of detected peaks. Default: 20. Decrease if objects are being merged together. Increase if objects are being over-split.\n",
    "- `MAXIMA_REDUCTION_FACTOR`: H-minima threshold for suppressing weak peaks (range: 0.0-1.0). Higher values = more aggressive suppression. If None, no h-minima filtering applied. Applied during seed detection (before watershed).\n",
    "\n",
    "**Shape Refinement**\n",
    "- `USE_SHAPE_REFINEMENT`: Apply boundary quality control after declumping. When enabled, evaluates watershed splits and rejects splits where the dividing boundary is long relative to perimeter.\n",
    "- `PROPORTION_THRESHOLD`: Boundary/perimeter ratio threshold for shape refinement. Only used when `USE_SHAPE_REFINEMENT=True`. Splits accepted if boundary_length / perimeter < proportion_threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set secondary object parameters\n",
    "SECOND_OBJ_DETECTION = False\n",
    "SECOND_OBJ_CHANNEL = None\n",
    "SECOND_OBJ_METHOD = None  # \"threshold\", \"cellpose\", or \"stardist\"\n",
    "\n",
    "# Common parameters (apply to all methods)\n",
    "SECOND_OBJ_MIN_SIZE = None\n",
    "SECOND_OBJ_MAX_SIZE = None\n",
    "SIZE_FILTER_METHOD = None\n",
    "MAX_OBJECTS_PER_CELL = None\n",
    "OVERLAP_THRESHOLD = None\n",
    "MAX_TOTAL_OBJECTS = None\n",
    "\n",
    "# Cellpose parameters (only used if SECOND_OBJ_METHOD == \"cellpose\")\n",
    "SECOND_OBJ_CELLPOSE_MODEL = \"cyto3\"\n",
    "SECOND_OBJ_DIAMETER = None  # None = auto-estimate, or specify in pixels\n",
    "SECOND_OBJ_FLOW_THRESHOLD = 0.4\n",
    "SECOND_OBJ_CELLPROB_THRESHOLD = 0.0\n",
    "\n",
    "# StarDist parameters (only used if SECOND_OBJ_METHOD == \"stardist\")\n",
    "SECOND_OBJ_STARDIST_MODEL = \"2D_versatile_fluo\"\n",
    "SECOND_OBJ_PROB_THRESHOLD = 0.5\n",
    "SECOND_OBJ_NMS_THRESHOLD = 0.4\n",
    "\n",
    "# Threshold method parameters (only used if SECOND_OBJ_METHOD == \"threshold\")\n",
    "RETURN_INTERMEDIATE_OUTPUTS = False\n",
    "THRESHOLD_SMOOTHING_SCALE = None\n",
    "THRESHOLD_METHOD = None\n",
    "USE_MORPHOLOGICAL_OPENING = False\n",
    "OPENING_DISK_RADIUS = None\n",
    "FILL_HOLES = None\n",
    "DECLUMP_METHOD = None\n",
    "DECLUMP_MODE = None\n",
    "SUPPRESS_LOCAL_MAXIMA = None\n",
    "MAXIMA_REDUCTION_FACTOR = None\n",
    "USE_SHAPE_REFINEMENT = None\n",
    "PROPORTION_THRESHOLD = None\n",
    "\n",
    "# Derive secondary object channel index from CHANNEL_NAMES\n",
    "if SECOND_OBJ_DETECTION:\n",
    "    SECOND_OBJ_CHANNEL_INDEX = CHANNEL_NAMES.index(SECOND_OBJ_CHANNEL)\n",
    "    \n",
    "    # Optionally estimate diameter for Cellpose if set to None\n",
    "    if SECOND_OBJ_METHOD == \"cellpose\" and SECOND_OBJ_DIAMETER is None:\n",
    "        from lib.phenotype.segment_secondary_object import estimate_second_obj_diameter\n",
    "        \n",
    "        print(f\"Estimating diameter for secondary objects in {SECOND_OBJ_CHANNEL} channel...\")\n",
    "        SECOND_OBJ_DIAMETER = estimate_second_obj_diameter(\n",
    "            aligned_image,\n",
    "            SECOND_OBJ_CHANNEL_INDEX,\n",
    "            method=\"cellpose\",\n",
    "            model_type=SECOND_OBJ_CELLPOSE_MODEL,\n",
    "            gpu=GPU\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segment secondary objects if enabled\n",
    "if SECOND_OBJ_DETECTION:\n",
    "    print(f\"Performing secondary object segmentation with {SECOND_OBJ_CHANNEL} using {SECOND_OBJ_METHOD} method...\")\n",
    "    \n",
    "    # Prepare nuclei centroids for distance calculations (optional)\n",
    "    nuclei_regions = measure.regionprops(nuclei)\n",
    "    nuclei_centroids_dict = {region.label: region.centroid for region in nuclei_regions}\n",
    "\n",
    "    if SECOND_OBJ_METHOD in [\"cellpose\", \"stardist\"]:\n",
    "        # ML-based segmentation\n",
    "        from lib.phenotype.segment_secondary_object import (\n",
    "            segment_second_objs_ml,\n",
    "            create_second_obj_boundary_visualization,\n",
    "            create_second_obj_standard_visualization,\n",
    "        )\n",
    "        \n",
    "        # Build ML parameters based on method\n",
    "        ml_params = {\n",
    "            'second_obj_method': SECOND_OBJ_METHOD,\n",
    "            'gpu': GPU,\n",
    "        }\n",
    "        \n",
    "        if SECOND_OBJ_METHOD == \"cellpose\":\n",
    "            ml_params.update({\n",
    "                'second_obj_cellpose_model': SECOND_OBJ_CELLPOSE_MODEL,\n",
    "                'second_obj_diameter': SECOND_OBJ_DIAMETER,\n",
    "                'second_obj_flow_threshold': SECOND_OBJ_FLOW_THRESHOLD,\n",
    "                'second_obj_cellprob_threshold': SECOND_OBJ_CELLPROB_THRESHOLD,\n",
    "            })\n",
    "        elif SECOND_OBJ_METHOD == \"stardist\":\n",
    "            ml_params.update({\n",
    "                'second_obj_stardist_model': SECOND_OBJ_STARDIST_MODEL,\n",
    "                'second_obj_prob_threshold': SECOND_OBJ_PROB_THRESHOLD,\n",
    "                'second_obj_nms_threshold': SECOND_OBJ_NMS_THRESHOLD,\n",
    "            })\n",
    "        \n",
    "        # Call ML segmentation\n",
    "        result = segment_second_objs_ml(\n",
    "            image=aligned_image,\n",
    "            second_obj_channel_index=SECOND_OBJ_CHANNEL_INDEX,\n",
    "            cell_masks=cells,\n",
    "            cytoplasm_masks=cytoplasms,\n",
    "            second_obj_min_size=SECOND_OBJ_MIN_SIZE,\n",
    "            second_obj_max_size=SECOND_OBJ_MAX_SIZE,\n",
    "            size_filter_method=SIZE_FILTER_METHOD,\n",
    "            max_objects_per_cell=MAX_OBJECTS_PER_CELL,\n",
    "            overlap_threshold=OVERLAP_THRESHOLD,\n",
    "            nuclei_centroids=nuclei_centroids_dict,\n",
    "            max_total_objects=MAX_TOTAL_OBJECTS,\n",
    "            **ml_params\n",
    "        )\n",
    "        \n",
    "        # Unpack outputs (ML methods don't return threshold_output)\n",
    "        second_obj_masks, cell_second_obj_table, updated_cytoplasms = result\n",
    "        threshold_output = None\n",
    "        \n",
    "    elif SECOND_OBJ_METHOD == \"threshold\":\n",
    "        # Traditional thresholding-based segmentation\n",
    "        from lib.phenotype.segment_secondary_object import (\n",
    "            segment_second_objs,\n",
    "            create_second_obj_boundary_visualization,\n",
    "            create_second_obj_standard_visualization,\n",
    "        )\n",
    "        \n",
    "        # Segment secondary objects with threshold method\n",
    "        result = segment_second_objs(\n",
    "            image=aligned_image,\n",
    "            second_obj_channel_index=SECOND_OBJ_CHANNEL_INDEX,\n",
    "            cell_masks=cells,\n",
    "            cytoplasm_masks=cytoplasms,\n",
    "            second_obj_min_size=SECOND_OBJ_MIN_SIZE,\n",
    "            second_obj_max_size=SECOND_OBJ_MAX_SIZE,\n",
    "            size_filter_method=SIZE_FILTER_METHOD,\n",
    "            threshold_smoothing_scale=THRESHOLD_SMOOTHING_SCALE,\n",
    "            threshold_method=THRESHOLD_METHOD,\n",
    "            use_morphological_opening=USE_MORPHOLOGICAL_OPENING,\n",
    "            opening_disk_radius=OPENING_DISK_RADIUS,\n",
    "            fill_holes=FILL_HOLES,\n",
    "            declump_method=DECLUMP_METHOD,\n",
    "            declump_mode=DECLUMP_MODE,\n",
    "            suppress_local_maxima=SUPPRESS_LOCAL_MAXIMA,\n",
    "            maxima_reduction_factor=MAXIMA_REDUCTION_FACTOR,\n",
    "            use_shape_refinement=USE_SHAPE_REFINEMENT,\n",
    "            proportion_threshold=PROPORTION_THRESHOLD,\n",
    "            max_objects_per_cell=MAX_OBJECTS_PER_CELL,\n",
    "            overlap_threshold=OVERLAP_THRESHOLD,\n",
    "            nuclei_centroids=nuclei_centroids_dict,\n",
    "            max_total_objects=MAX_TOTAL_OBJECTS,\n",
    "            return_threshold_output=RETURN_INTERMEDIATE_OUTPUTS,\n",
    "        )\n",
    "        \n",
    "        # Unpack outputs (threshold method may return threshold_output)\n",
    "        second_obj_masks, cell_second_obj_table, updated_cytoplasms, *opt = result\n",
    "        threshold_output = opt[0] if opt else None\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(f\"Unknown SECOND_OBJ_METHOD: {SECOND_OBJ_METHOD}. Use 'threshold', 'cellpose', or 'stardist'\")\n",
    "\n",
    "    cell_summary = cell_second_obj_table[\"cell_summary\"]\n",
    "\n",
    "    # Print statistics\n",
    "    print(f\"Found secondary objects in {cell_summary['has_second_obj'].sum()} out of {len(cell_summary)} cells\")\n",
    "    print(f\"Average objects per cell with objects: {cell_summary.loc[cell_summary['has_second_obj'], 'num_second_objs'].mean():.2f}\")\n",
    "    print(f\"Average secondary object area ratio: {cell_summary['second_obj_area_ratio'].mean():.4f}\")\n",
    "\n",
    "    # Create standard visualizations\n",
    "    print(\"Example microplots:\")\n",
    "    panel = create_second_obj_standard_visualization(\n",
    "        aligned_image,\n",
    "        SECOND_OBJ_CHANNEL_INDEX,\n",
    "        SECOND_OBJ_CHANNEL,\n",
    "        second_obj_masks,\n",
    "        threshold_output=threshold_output,\n",
    "    )\n",
    "    plt.show()\n",
    "\n",
    "    # Create enhanced boundary visualization\n",
    "    print(\"Enhanced visualization with cell boundaries and secondary object boundaries:\")\n",
    "    boundary_panel = create_second_obj_boundary_visualization(\n",
    "        aligned_image,\n",
    "        SECOND_OBJ_CHANNEL_INDEX,\n",
    "        cell_masks=cells,\n",
    "        second_obj_masks=second_obj_masks,\n",
    "        channel_names=CHANNEL_NAMES,\n",
    "        channel_cmaps=CHANNEL_CMAPS,\n",
    "    )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SECOND_OBJ_DETECTION:\n",
    "    # Extract phenotype features for secondary objects\n",
    "    from lib.phenotype.extract_phenotype_second_objs import extract_phenotype_second_objs\n",
    "\n",
    "    second_obj_phenotype = extract_phenotype_second_objs(\n",
    "        aligned_image,\n",
    "        second_objs=second_obj_masks,\n",
    "        second_obj_cell_mapping_df=cell_second_obj_table['second_obj_cell_mapping'],\n",
    "        wildcards=WILDCARDS,\n",
    "        foci_channel=FOCI_CHANNEL_INDEX, \n",
    "        channel_names=CHANNEL_NAMES\n",
    "    )\n",
    "\n",
    "    average_diameter = second_obj_phenotype['second_obj_diameter'].mean()\n",
    "    print(f\"Average diameter of secondary objects: {average_diameter}\")\n",
    "    average_area = second_obj_phenotype['second_obj_area'].mean()\n",
    "    print(f\"Average area of secondary objects: {average_area}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SECOND_OBJ_DETECTION:\n",
    "    # Display feature list\n",
    "    second_obj_feature_cols = [\n",
    "        col for col in second_obj_phenotype.columns \n",
    "        if col not in [\"label\", \"well\", \"tile\", \"cell_label\"]\n",
    "    ]\n",
    "    print(f\"\\nNumber of secondary object features: {len(second_obj_feature_cols)}\")\n",
    "\n",
    "    # Apply the function to remove channel names\n",
    "    second_obj_feature_types = [\n",
    "        remove_channel_name(feature, CHANNEL_NAMES) \n",
    "        for feature in second_obj_feature_cols\n",
    "    ]\n",
    "\n",
    "    # Get unique feature types\n",
    "    second_obj_unique_types = sorted(set(second_obj_feature_types))\n",
    "\n",
    "    print(\"Unique secondary object feature types:\")\n",
    "    display(second_obj_unique_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add phenotype process parameters to config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add phenotype section\n",
    "config[\"phenotype\"] = {\n",
    "    \"foci_channel_index\": FOCI_CHANNEL_INDEX,\n",
    "    \"channel_names\": CHANNEL_NAMES,\n",
    "    \"align\": ALIGN,\n",
    "    \"dapi_index\": DAPI_INDEX,\n",
    "    \"cyto_index\": CYTO_INDEX,\n",
    "    \"segmentation_method\": SEGMENTATION_METHOD,\n",
    "    \"reconcile\": RECONCILE,\n",
    "    \"gpu\": GPU,\n",
    "    \"cp_method\": CP_METHOD,\n",
    "}\n",
    "\n",
    "# Add method-specific parameters based on segmentation method\n",
    "if SEGMENTATION_METHOD == \"cellpose\":\n",
    "    config[\"phenotype\"].update({\n",
    "        \"nuclei_diameter\": NUCLEI_DIAMETER,\n",
    "        \"cell_diameter\": CELL_DIAMETER,\n",
    "        \"nuclei_flow_threshold\": NUCLEI_FLOW_THRESHOLD,\n",
    "        \"nuclei_cellprob_threshold\": NUCLEI_CELLPROB_THRESHOLD,\n",
    "        \"cell_flow_threshold\": CELL_FLOW_THRESHOLD,\n",
    "        \"cell_cellprob_threshold\": CELL_CELLPROB_THRESHOLD,\n",
    "        \"cellpose_model\": CELLPOSE_MODEL,\n",
    "    })\n",
    "    # Add helper_index only if it's defined\n",
    "    if HELPER_INDEX is not None:\n",
    "        config[\"phenotype\"][\"helper_index\"] = HELPER_INDEX\n",
    "elif SEGMENTATION_METHOD == \"stardist\":\n",
    "    config[\"phenotype\"].update({\n",
    "        \"stardist_model\": STARDIST_MODEL,\n",
    "        \"nuclei_prob_threshold\": NUCLEI_PROB_THRESHOLD,\n",
    "        \"nuclei_nms_threshold\": NUCLEI_NMS_THRESHOLD,\n",
    "        \"cell_prob_threshold\": CELL_PROB_THRESHOLD,\n",
    "        \"cell_nms_threshold\": CELL_NMS_THRESHOLD,\n",
    "    })\n",
    "\n",
    "# Add alignment parameters if defined\n",
    "if ALIGN:  \n",
    "    config[\"phenotype\"][\"target\"] = TARGET_INDEX\n",
    "    config[\"phenotype\"][\"source\"] = SOURCE_INDEX\n",
    "    config[\"phenotype\"][\"riders\"] = RIDER_INDEXES\n",
    "    config[\"phenotype\"][\"remove_channel\"] = REMOVE_CHANNEL\n",
    "    config[\"phenotype\"][\"upsample_factor\"] = UPSAMPLE_FACTOR\n",
    "    config[\"phenotype\"][\"window\"] = WINDOW\n",
    "\n",
    "# Add secondary object detection parameters\n",
    "if SECOND_OBJ_DETECTION:\n",
    "    # Determine if using ML-based segmentation method\n",
    "    use_ml_segmentation = SECOND_OBJ_METHOD in [\"cellpose\", \"stardist\"]\n",
    "    # Common parameters for all methods\n",
    "    config[\"phenotype\"].update({\n",
    "        \"second_obj_detection\": SECOND_OBJ_DETECTION,\n",
    "        \"second_obj_channel_index\": SECOND_OBJ_CHANNEL_INDEX,\n",
    "        \"second_obj_method\": SECOND_OBJ_METHOD,\n",
    "        \"use_ml_segmentation\": use_ml_segmentation,\n",
    "        \"second_obj_min_size\": SECOND_OBJ_MIN_SIZE,\n",
    "        \"second_obj_max_size\": SECOND_OBJ_MAX_SIZE,\n",
    "        \"size_filter_method\": SIZE_FILTER_METHOD,\n",
    "        \"max_objects_per_cell\": MAX_OBJECTS_PER_CELL,\n",
    "        \"overlap_threshold\": OVERLAP_THRESHOLD,\n",
    "        \"max_total_objects\": MAX_TOTAL_OBJECTS,\n",
    "    })\n",
    "    \n",
    "    # Add method-specific parameters\n",
    "    if SECOND_OBJ_METHOD == \"cellpose\":\n",
    "        config[\"phenotype\"].update({\n",
    "            \"second_obj_cellpose_model\": SECOND_OBJ_CELLPOSE_MODEL,\n",
    "            \"second_obj_diameter\": SECOND_OBJ_DIAMETER,\n",
    "            \"second_obj_flow_threshold\": SECOND_OBJ_FLOW_THRESHOLD,\n",
    "            \"second_obj_cellprob_threshold\": SECOND_OBJ_CELLPROB_THRESHOLD,\n",
    "        })\n",
    "    elif SECOND_OBJ_METHOD == \"stardist\":\n",
    "        config[\"phenotype\"].update({\n",
    "            \"second_obj_stardist_model\": SECOND_OBJ_STARDIST_MODEL,\n",
    "            \"second_obj_prob_threshold\": SECOND_OBJ_PROB_THRESHOLD,\n",
    "            \"second_obj_nms_threshold\": SECOND_OBJ_NMS_THRESHOLD,\n",
    "        })\n",
    "    elif SECOND_OBJ_METHOD == \"threshold\":\n",
    "        config[\"phenotype\"].update({\n",
    "            \"threshold_smoothing_scale\": THRESHOLD_SMOOTHING_SCALE,\n",
    "            \"threshold_method\": THRESHOLD_METHOD,\n",
    "            \"use_morphological_opening\": USE_MORPHOLOGICAL_OPENING,\n",
    "            \"opening_disk_radius\": OPENING_DISK_RADIUS,\n",
    "            \"fill_holes\": FILL_HOLES,\n",
    "            \"declump_method\": DECLUMP_METHOD,\n",
    "            \"declump_mode\": DECLUMP_MODE,\n",
    "            \"suppress_local_maxima\": SUPPRESS_LOCAL_MAXIMA,\n",
    "            \"maxima_reduction_factor\": MAXIMA_REDUCTION_FACTOR,\n",
    "            \"use_shape_refinement\": USE_SHAPE_REFINEMENT,\n",
    "            \"proportion_threshold\": PROPORTION_THRESHOLD,\n",
    "        })\n",
    "\n",
    "# Add custom channel offsets if defined\n",
    "if CUSTOM_CHANNEL_OFFSETS:\n",
    "    config[\"phenotype\"][\"custom_channel_offsets\"] = CUSTOM_CHANNEL_OFFSETS_INDEXED\n",
    "\n",
    "# Convert tuples to lists before dumping\n",
    "safe_config = convert_tuples_to_lists(config)\n",
    "\n",
    "# Write the updated configuration back with markdown-style comments\n",
    "with open(CONFIG_FILE_PATH, \"w\") as config_file:\n",
    "    # Write the introductory markdown-style comments\n",
    "    config_file.write(CONFIG_FILE_HEADER)\n",
    "\n",
    "    # Dump the updated YAML structure, keeping markdown comments for sections\n",
    "    yaml.dump(safe_config, config_file, default_flow_style=False, sort_keys=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brieflow_ramon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
